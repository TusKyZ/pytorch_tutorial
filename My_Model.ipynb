{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR6MuggUQNW0hnLHaNgCtO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TusKyZ/pytorch_tutorial/blob/main/My_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilpCv7DNA1kH"
      },
      "outputs": [],
      "source": [
        "#My model for using to classify the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Imports\n",
        "import torch\n",
        "import torchvision ## Contains some utilities for working with the image data\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "cj1g_7UnA--4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root = 'data/', download = True)\n",
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KjBvpyeBDQo",
        "outputId": "532b239d-2d50-4507-d9f9-808ceaa430b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 126MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 29.7MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 94.3MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MNIST dataset(images and labels)\n",
        "mnist_dataset = MNIST(root = 'data/', train = True, transform = transforms.ToTensor())\n",
        "print(mnist_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHz594QZBRr1",
        "outputId": "020f1ca8-906f-4edf-ff52-f0bfe8b029a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, validation_data = random_split(mnist_dataset, [50000, 10000])\n",
        "## Print the length of train and validation datasets\n",
        "print(\"length of Train Datasets: \", len(train_data))\n",
        "print(\"length of Validation Datasets: \", len(validation_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3USHGBT4BGsC",
        "outputId": "17af22e2-aaae-4d27-d4c0-6234f60a96bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of Train Datasets:  50000\n",
            "length of Validation Datasets:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "z673MNEwBdEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class SimpleClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        # We pack the entire architecture into one \"Sequential\" box.\n",
        "        # This handles the order of operations for us.\n",
        "        self.net = nn.Sequential(\n",
        "            # Input -> Hidden Layer 1\n",
        "            nn.Linear(num_inputs, 500),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Hidden Layer 1 -> Hidden Layer 2\n",
        "            nn.Linear(500, 300),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Hidden Layer 2 -> Hidden Layer 3\n",
        "            nn.Linear(300, 100),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Hidden Layer 3 -> Output Layer\n",
        "            nn.Linear(100, num_outputs)\n",
        "            # Note: No ReLU, We need raw scores (logits) for the loss function.\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = SimpleClassifier(num_inputs=784, num_outputs=10) #input 784 (pixels) and output being 10 (0-9)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89vxLdkaBIiI",
        "outputId": "685f7e87-34e9-4679-f215-3762fadb1292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=500, out_features=300, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}